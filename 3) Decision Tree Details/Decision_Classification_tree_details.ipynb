{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SOrSoPFO34A6"},"source":["# **Decision Tree Details**"]},{"cell_type":"markdown","metadata":{"id":"laF9H-hv362d"},"source":["## **1 Introduction**"]},{"cell_type":"markdown","metadata":{"id":"OQt_0Mlp4WJe"},"source":["## **2 Experiment Code**"]},{"cell_type":"code","metadata":{"id":"JjZWCGp_4m8O","executionInfo":{"status":"ok","timestamp":1689704074015,"user_tz":180,"elapsed":11,"user":{"displayName":"ISMAEL JEFTE","userId":"09349419826463979418"}}},"source":["import pandas as pd\n","import math\n","import numpy as np"],"execution_count":61,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EzlF8_PG5hkT"},"source":["### **2.2 Superparameter definition section**\n","\n"]},{"cell_type":"code","metadata":{"id":"_CGac9hf50p-","executionInfo":{"status":"ok","timestamp":1689704100973,"user_tz":180,"elapsed":1042,"user":{"displayName":"ISMAEL JEFTE","userId":"09349419826463979418"}}},"source":["#algorithm = \"Regression\" # Algorithm: Classification, Regression\n","algorithm = \"Classification\" # Algorithm: Classification, Regression\n","\n","# Dataset1: Text features and text labels\n","df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQARjcPfQ5nAvsM3Rf9mQsZpUZ7eh1kKNBhsopX7ZEcU1N0bHLoqXm_KrL-xat8xISY3_8tfiALGNu8/pub?output=csv\")\n","\n","# Dataset2: Mix features and Numeric labels, here you have to change the path to yours.\n","#df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQARjcPfQ5nAvsM3Rf9mQsZpUZ7eh1kKNBhsopX7ZEcU1N0bHLoqXm_KrL-xat8xISY3_8tfiALGNu8/pub?output=csv\")\n","\n","# This dictionary is used to store feature types of continuous numeric features and discrete literal features for subsequent judgment\n","dataset_features = dict()\n","num_of_columns = df.shape[1]-1\n","#The data type of each column of the data is saved for displaying the data name\n","for i in range(0, num_of_columns):\n","    #Gets the column name and holds the characteristics of a column of data by column\n","    column_name = df.columns[i]\n","    #Save the type of the data\n","    dataset_features[column_name] = df[column_name].dtypes\n","    # The size of the indent when display\n","    root = 1\n","# If the algorithm selects a regression tree but the label is not a continuous value, an error is reported\n","if 'Regression' in df.columns:\n","  if algorithm == 'Regression':\n","      if df['Decision'].dtypes == 'object':\n","          raise ValueError('dataset wrong')\n","# If the tag value is continuous, the regression tree must be used\n","if 'Decision' in df.columns:\n","    if df['Decision'].dtypes != 'object':\n","        algorithm = 'Regression'\n","        global_stdev = df['Decision'].std(ddof=0)\n","\n"],"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hp7m5JvS6Bz9"},"source":["### **2.3 Define the functions required to complete the algorithm**"]},{"cell_type":"markdown","metadata":{"id":"QuDsTgeR6Kkz"},"source":["#### **Step 1**\n","\n","ProcessContinuousFeatures: Used to convert a continuous digital feature into a category feature."]},{"cell_type":"code","metadata":{"id":"BJBIo4i36WwX","executionInfo":{"status":"ok","timestamp":1689703948220,"user_tz":180,"elapsed":404,"user":{"displayName":"ISMAEL JEFTE","userId":"09349419826463979418"}}},"source":["# This function is used to handle numeric characteristics\n","def processContinuousFeatures(cdf, column_name, entropy):\n","    # Numerical features are arranged in order\n","    unique_values = sorted(cdf[column_name].unique())\n","    subset_ginis = [];\n","    subset_red_stdevs = []\n","    for i in range(0, len(unique_values) - 1):\n","        threshold = unique_values[i]\n","        # Find the segmentation result if the first number is used as the threshold\n","        subset1 = cdf[cdf[column_name] <= threshold]\n","        subset2 = cdf[cdf[column_name] > threshold]\n","        # Calculate the proportion occupied by dividing the two parts\n","        subset1_rows = subset1.shape[0];\n","        subset2_rows = subset2.shape[0]\n","        total_instances = cdf.shape[0]\n","    # In the text feature part, entropy is calculated by using the cycle,\n","    # and in the numeric part, entropy is calculated by using the two groups after segmentation,\n","    # and the degree of entropy reduction is obtained\n","    if algorithm == 'Classification':\n","        decision_for_subset1 = subset1['Decision'].value_counts().tolist()\n","        decision_for_subset2 = subset2['Decision'].value_counts().tolist()\n","\n","        gini_subset1 = 1;\n","        gini_subset2 = 1\n","\n","        for j in range(0, len(decision_for_subset1)):\n","            gini_subset1 = gini_subset1 - math.pow((decision_for_subset1[j] / subset1_rows), 2)\n","\n","        for j in range(0, len(decision_for_subset2)):\n","            gini_subset2 = gini_subset2 - math.pow((decision_for_subset2[j] / subset2_rows), 2)\n","\n","        gini = (subset1_rows / total_instances) * gini_subset1 + (subset2_rows / total_instances) * gini_subset2\n","\n","        subset_ginis.append(gini)\n","    # Take standard deviation as the judgment basis, calculate the decrease value of standard deviation at this time\n","    elif algorithm == 'Regression':\n","        superset_stdev = cdf['Decision'].std(ddof=0)\n","        subset1_stdev = subset1['Decision'].std(ddof=0)\n","        subset2_stdev = subset2['Decision'].std(ddof=0)\n","\n","        threshold_weighted_stdev = (subset1_rows / total_instances) * subset1_stdev + (subset2_rows / total_instances) * subset2_stdev\n","        threshold_reducted_stdev = superset_stdev - threshold_weighted_stdev\n","        subset_red_stdevs.append(threshold_reducted_stdev)\n","\n","    #Find the index of the split value\n","    if algorithm == \"Classification\":\n","        winner_one = subset_ginis.index(min(subset_ginis))\n","    elif algorithm == \"Regression\":\n","        winner_one = subset_red_stdevs.index(max(subset_red_stdevs))\n","    # Find the corresponding value according to the index\n","    winner_threshold = unique_values[winner_one]\n","    # Converts the original data column to an edited string column.\n","    # Characters smaller than the threshold are modified with the <= threshold value\n","    cdf[column_name] = np.where(cdf[column_name] <= winner_threshold, \"<=\" + str(winner_threshold),\">\" + str(winner_threshold))\n","    return cdf"],"execution_count":55,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gK7WpHrr7vkX"},"source":["#### **Step 2**\n","\n","CalculateEntropy: Used to calculate Gini or variances, they are the criteria for classifying."]},{"cell_type":"code","metadata":{"id":"LMOByXSK73G7","executionInfo":{"status":"ok","timestamp":1689703952369,"user_tz":180,"elapsed":397,"user":{"displayName":"ISMAEL JEFTE","userId":"09349419826463979418"}}},"source":["# This function calculates the entropy of the column, and the input data must contain the Decision column\n","def calculateEntropy(df):\n","    # The regression tree entropy is 0\n","    if algorithm == 'Regression':\n","        return 0\n","\n","    rows = df.shape[0]\n","    # Use Value_counts to get all values stored as dictionaries, keys: finds keys, and Tolist: change to lists.\n","    # This line of code finds the tag value.\n","    decisions = df['Decision'].value_counts().keys().tolist()\n","    entropy = 0\n","\n","    # Here the loop traverses all the tags\n","    for i in range(0, len(decisions)):\n","        # Record the number of times the tag value appears\n","        num_of_decisions = df['Decision'].value_counts().tolist()[i]\n","        # probability of occurrence\n","        class_probability = num_of_decisions / rows\n","        # Calculate the entropy and sum it up\n","        entropy = entropy - class_probability * math.log(class_probability, 2)\n","\n","    return entropy"],"execution_count":56,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"guyzSUDN9Hf_"},"source":["#### **Step 3**\n","\n","FindDecision: Find which feature in the current data to classify.\n"]},{"cell_type":"code","metadata":{"id":"mzfwg4iI9sBP","executionInfo":{"status":"ok","timestamp":1689703956576,"user_tz":180,"elapsed":406,"user":{"displayName":"ISMAEL JEFTE","userId":"09349419826463979418"}}},"source":["def findDecision(ddf):\n","    # If it's a regression tree, then you take the standard deviation of the true value\n","    if algorithm == 'Regression':\n","        stdev = ddf['Decision'].std(ddof=0)\n","\n","    # Get the entropy of the decision column\n","    entropy = calculateEntropy(ddf)\n","    columns = ddf.shape[1];\n","    rows = ddf.shape[0]\n","\n","    # Used to store Gini and standard deviation values\n","    ginis = [];\n","    reducted_stdevs = []\n","\n","    # Traverse all columns and calculate the relevant indexes of all columns according to algorithm selection\n","    for i in range(0, columns - 1):\n","        column_name = ddf.columns[i]\n","        column_type = ddf[column_name].dtypes\n","        # Determine if the column feature is a number, and if so, process the data using the following function,\n","        # which modifies the data to a string type category on return.\n","        # The idea is to directly use character characteristics, continuous digital characteristics into discrete character characteristics\n","    if column_type != 'object':\n","        ddf = processContinuousFeatures(ddf, column_name, entropy)\n","        # The statistical data in this column can be obtained, and the continuous data can be directly classified after processing,\n","        # and the categories are less than the threshold and greater than the threshold\n","    classes = ddf[column_name].value_counts()\n","    gini = 0;\n","    weighted_stdev = 0\n","    # Start the loop with the type of data in the column\n","    for j in range(0, len(classes)):\n","        current_class = classes.keys().tolist()[j]\n","        # The final classification result corresponding to the data is selected\n","        # by deleting the value of the df column equal to the current data\n","        subdataset = ddf[ddf[column_name] == current_class]\n","        subset_instances = subdataset.shape[0]\n","        # The entropy of information is calculated here\n","        if algorithm == 'Classification': # GINI index\n","            decision_list = subdataset['Decision'].value_counts().tolist()\n","\n","            subgini = 1\n","\n","            for k in range(0, len(decision_list)):\n","                subgini = subgini - math.pow((decision_list[k] / subset_instances), 2)\n","\n","            gini = gini + (subset_instances / rows) * subgini\n","        # The regression tree is judged by the standard deviation,\n","        # and the standard deviation of the subclasses in this column is calculated here\n","        elif algorithm == 'Regression':\n","            subset_stdev = subdataset['Decision'].std(ddof=0)\n","            weighted_stdev = weighted_stdev + (subset_instances / rows) * subset_stdev\n","\n","    # Used to store the final value of this column\n","    if algorithm == \"Classification\":\n","        ginis.append(gini)\n","    # Store the decrease in standard deviation for all columns\n","    elif algorithm == 'Regression':\n","        reducted_stdev = stdev - weighted_stdev\n","        reducted_stdevs.append(reducted_stdev)\n","\n","    # Determine which column is the first branch\n","    # by selecting the index of the largest value from the list of evaluation indicators\n","    if algorithm == \"Classification\":\n","        winner_index = ginis.index(min(ginis))\n","    elif algorithm == \"Regression\":\n","        winner_index = reducted_stdevs.index(max(reducted_stdevs))\n","\n","    winner_name = ddf.columns[winner_index]\n","\n","    return winner_name"],"execution_count":57,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b1BR_nGr_OR2"},"source":["#### **Step 4**\n","\n","FormatRule: Standardize the final output format."]},{"cell_type":"code","metadata":{"id":"Ay5JWAZY_WjF","executionInfo":{"status":"ok","timestamp":1689703964282,"user_tz":180,"elapsed":418,"user":{"displayName":"ISMAEL JEFTE","userId":"09349419826463979418"}}},"source":["# ROOT is a number used to generate ' 'to adjust the display format of the decision making process\n","def formatRule(root):\n","    resp = ''\n","\n","    for i in range(0, root):\n","        resp = resp + ' '\n","\n","    return resp"],"execution_count":58,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNgMFreH_2FP"},"source":["#### **Step 5**\n","\n","BuildDecisionTree: Main function."]},{"cell_type":"code","metadata":{"id":"iMO91koI_-o1","executionInfo":{"status":"ok","timestamp":1689703967690,"user_tz":180,"elapsed":429,"user":{"displayName":"ISMAEL JEFTE","userId":"09349419826463979418"}}},"source":["# With this function, you build the decision tree model,\n","# entering data in dataframe format, the root value, and the file address\n","# If the value in the column is literal, it branches directly by literal category\n","def buildDecisionTree(df, root):\n","    # Identify the different charForResp\n","    charForResp = \"'\"\n","    if algorithm == 'Regression':\n","        charForResp = \"\"\n","\n","    tmp_root = root * 1\n","\n","    df_copy = df.copy()\n","    # Output the winning column of the decision tree, enter a list,\n","    # and output the column name of the decision column in the list\n","    winner_name = findDecision(df)\n","\n","    # Determines whether the winning column is a number or a character\n","    numericColumn = False\n","    if dataset_features[winner_name] != 'object':\n","        numericColumn = True\n","\n","    # To ensure the integrity of the original data and prevent the data from changing,\n","    # mainly to ensure that the data of other columns besides the winning column does not change,\n","    # so as to continue the branch in the next step.\n","    columns = df.shape[1]\n","    for i in range(0, columns - 1):\n","        column_name = df.columns[i]\n","        if df[column_name].dtype != 'object' and column_name != winner_name:\n","            df[column_name] = df_copy[column_name]\n","        # Find the element in the branching column\n","    classes = df[winner_name].value_counts().keys().tolist()\n","    # Traversing all classes in the branch column has two functions:\n","    # 1. Display which class is currently traversed to; 2. Determine whether the current class is already leaf node\n","    for i in range(0, len(classes)):\n","        # Find the Subdataset as in FindDecision, but discard this column of the current branch\n","        current_class = classes[i]\n","        subdataset = df[df[winner_name] == current_class]\n","        # At the same time, the data of the first branch column is discarded and the remaining data is processed\n","        subdataset = subdataset.drop(columns=[winner_name])\n","        # Edit the display situation. If it is a numeric feature, the character conversion has been completed when searching for branches.\n","        #If it is not a character feature, it is displayed with column names\n","        if numericColumn == True:\n","            compareTo = current_class # current class might be <=x or >x in this case\n","        else:\n","            compareTo = \" == '\" + str(current_class) + \"'\"\n","            terminateBuilding = False\n","        # -----------------------------------------------\n","        # This determines whether it is already the last leaf node\n","        if len(subdataset['Decision'].value_counts().tolist()) == 1:\n","            final_decision = subdataset['Decision'].value_counts().keys().tolist()[0] # all items are equal in this case\n","            terminateBuilding = True\n","        # At this time, only the Decision column is left, that is, all the segmentation features have been used\n","        elif subdataset.shape[1] == 1:\n","            # get the most frequent one\n","            final_decision = subdataset['Decision'].value_counts().idxmax()\n","            terminateBuilding = True\n","        # The regression tree is judged as leaf node if the number of elements is less than 5\n","        #elif algorithm == 'Regression' and subdataset.shape[0] < 5: # pruning condition\n","        # Another criterion is to take the standard deviation as the criterion and the sample mean in the node as the value of the node\n","        elif algorithm == 'Regression' and subdataset['Decision'].std(ddof=0)/global_stdev < 0.4:\n","            # get average\n","            final_decision = subdataset['Decision'].mean()\n","            terminateBuilding = True\n","        # -----------------------------------------------\n","        # Here we begin to output the branching results of the decision tree.。\n","        print(formatRule(root), \"if \", winner_name, compareTo, \":\")\n","        # -----------------------------------------------\n","        # check decision is made\n","        if terminateBuilding == True:\n","            print(formatRule(root + 1), \"return \", charForResp + str(final_decision) + charForResp)\n","        else: # decision is not made, continue to create branch and leafs\n","            # The size of the indent at display represented by root\n","            root = root + 1\n","            # Call this function again for the next loop\n","            buildDecisionTree(subdataset, root)\n","\n","        root = tmp_root * 1"],"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yDJ4VItEAKHx"},"source":["### **2.4 Execute the code**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CWZizeuARe_","outputId":"b0bc5ffa-6f90-4b9a-a686-232907ca0fe6","executionInfo":{"status":"ok","timestamp":1689704108630,"user_tz":180,"elapsed":401,"user":{"displayName":"ISMAEL JEFTE","userId":"09349419826463979418"}}},"source":["# call the function\n","buildDecisionTree(df, root)"],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["  if  Outlook  == 'Sunny' :\n","   if  Temperature  == 'Hot' :\n","    return  'No'\n","   if  Temperature  == 'Mild' :\n","    if  Humidity  == 'High' :\n","     return  'No'\n","    if  Humidity  == 'Normal' :\n","     return  'Yes'\n","   if  Temperature  == 'Cool' :\n","    return  'Yes'\n","  if  Outlook  == 'Rain' :\n","   if  Temperature  == 'Mild' :\n","    if  Humidity  == 'High' :\n","     if  Wind  == 'Weak' :\n","      return  'Yes'\n","     if  Wind  == 'Strong' :\n","      return  'No'\n","    if  Humidity  == 'Normal' :\n","     return  'Yes'\n","   if  Temperature  == 'Cool' :\n","    if  Humidity  == 'Normal' :\n","     if  Wind  == 'Weak' :\n","      return  'Yes'\n","     if  Wind  == 'Strong' :\n","      return  'No'\n","  if  Outlook  == 'Overcast' :\n","   return  'Yes'\n"]}]},{"cell_type":"code","source":["print(df.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esQkjYfgK3mh","executionInfo":{"status":"ok","timestamp":1689703618442,"user_tz":180,"elapsed":406,"user":{"displayName":"ISMAEL JEFTE","userId":"09349419826463979418"}},"outputId":"ff46fd8b-dfb2-4556-ff6a-535e6b5e85a7"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["    Outlook Temperature Humidity    Wind Decision\n","0     Sunny         Hot     High    Weak       No\n","1     Sunny         Hot     High  Strong       No\n","2  Overcast         Hot     High    Weak      Yes\n","3      Rain        Mild     High    Weak      Yes\n","4      Rain        Cool   Normal    Weak      Yes\n"]}]}]}